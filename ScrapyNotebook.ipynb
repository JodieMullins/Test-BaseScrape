{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path \n",
    "import scrapy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(virt) PS C:\\Users\\jomuf\\Documents\\CODE YOU\\Test-BaseScrape> scrapy startproject SpiderCrawling\n",
    "New Scrapy project 'SpiderCrawling', using template directory 'C:\\Users\\jomuf\\Documents\\CODE YOU\\Test-BaseScrape\\virt\\Lib\\site-packages\\scrapy\\templates\\project', created in:\n",
    "    C:\\Users\\jomuf\\Documents\\CODE YOU\\Test-BaseScrape\\SpiderCrawling\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(virt) PS C:\\Users\\jomuf\\Documents\\CODE YOU\\Test-BaseScrape\\SpiderCrawling> cd SpiderCrawling       \n",
    "(virt) PS C:\\Users\\jomuf\\Documents\\CODE YOU\\Test-BaseScrape\\SpiderCrawling\\SpiderCrawling> cd spiders       \n",
    "(virt) PS C:\\Users\\jomuf\\Documents\\CODE YOU\\Test-BaseScrape\\SpiderCrawling\\SpiderCrawling\\spiders> ls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(virt) PS C:\\Users\\jomuf\\Documents\\CODE YOU\\Test-BaseScrape\\SpiderCrawling\\SpiderCrawling\\spiders> scrapy genspider bookspider books.toscrape.com\n",
    "Created spider 'bookspider' using template 'basic' in module:\n",
    "  SpiderCrawling.spiders.bookspider\n",
    "(virt) PS C:\\Users\\jomuf\\Documents\\CODE YOU\\Test-BaseScrape\\SpiderCrawling\\SpiderCrawling\\spiders> ls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(virt) PS C:\\Users\\jomuf\\Documents\\CODE YOU\\Test-BaseScrape\\SpiderCrawling\\SpiderCrawling\\spiders> pip install ipython"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(virt) PS C:\\Users\\jomuf\\Documents\\CODE YOU\\Test-BaseScrape\\SpiderCrawling\\SpiderCrawling\\spiders> scrapy shell"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "In [1]: fetch('https://books.toscrape.com/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    ".txt> (referer: None)\n",
    "2024-02-02 12:14:57 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://books.toscrape.com/> (referer: None)\n",
    "\n",
    "2024-02-02 12:14:58 [asyncio] DEBUG: Using selector: SelectSelector\n",
    "In [2]: response\n",
    "Out[2]: <200 https://books.toscrape.com/>\n",
    "\n",
    "2024-02-02 12:16:10 [asyncio] DEBUG: Using selector: SelectSelector\n",
    "In [3]: response.css('article.product_pod')\n",
    "Out[3]:\n",
    "[<Selector query=\"descendant-or-self::article[@class and contains(concat(' ', normalize-space(@class), ' '), ' product_pod ')]\" data='<article class=\"product_pod\">\\n       ...'>,\n",
    " <Selector query=\"descendant-or-self::article[@class and contains(concat(' ', normalize-space(@class), ' '), '"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "2024-02-02 12:19:00 [asyncio] DEBUG: Using selector: SelectSelector\n",
    "In [4]: books = response.css('article.product_pod')\n",
    "\n",
    "2024-02-02 12:20:04 [asyncio] DEBUG: Using selector: SelectSelector\n",
    "In [5]: book = books[0]\n",
    "\n",
    "2024-02-02 13:50:30 [asyncio] DEBUG: Using selector: SelectSelector\n",
    "In [6]: book.css('h3 a::text').get()\n",
    "Out[6]: 'A Light in the ...'\n",
    "\n",
    "2024-02-02 13:51:46 [asyncio] DEBUG: Using selector: SelectSelector\n",
    "In [7]: book.css('.product_price .price_color::text').get()\n",
    "Out[7]: 'Â£51.77'\n",
    "\n",
    "2024-02-02 13:52:50 [asyncio] DEBUG: Using selector: SelectSelector\n",
    "In [8]: book.css('h3 a').attrib['href']\n",
    "Out[8]: 'catalogue/a-light-in-the-attic_1000/index.html'\n",
    "\n",
    "2024-02-02 13:54:22 [asyncio] DEBUG: Using selector: SelectSelector\n",
    "In [9]: book.css('h3 a').attrib['title']\n",
    "Out[9]: 'A Light in the Attic'\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "AFTER THE PREVIOUS STEPS HAVE BEEN COMPLETED, MUST INSERT VALUES SOUGHT INTO BOOKSPIDER.PY (NAMED SPIDER FILE)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ORIGINAL CODE : CODE ACADEMY\n",
    "\n",
    "import scrapy\n",
    "\n",
    "\n",
    "class BookspiderSpider(scrapy.Spider):\n",
    "    name = \"bookspider\"\n",
    "    allowed_domains = [\"books.toscrape.com\"]\n",
    "    start_urls = [\"https://books.toscrape.com\"]\n",
    "\n",
    "    def parse(self, response):\n",
    "        books = response.css('article.product_pod')\n",
    "\n",
    "# Insert loop to iterate down the page for each unit called\n",
    "        for book in books:\n",
    "            # We need to hold value of a sequence\n",
    "            yield{\n",
    "\n",
    "            # Changed name to include full title\n",
    "                'name' : book.css('h3 a').attrib['title'],\n",
    "                'price' : book.css('.product_price .price_color::text').get(),\n",
    "                'url' : book.css('h3 a').attrib['href'],\n",
    "            }\n",
    "\n",
    "        # to ensure the iteration loops through following pages\n",
    "        next_page = response.css('li.next a ::attr(href)').get()\n",
    "\n",
    "        if next_page is not None:\n",
    "            if 'catalogue/' in next_page:\n",
    "                next_page_url = 'https://books.toscrape.com/' + next_page\n",
    "            else:\n",
    "                next_page_url = 'https://books.toscrape.com/catalogue/' + next_page\n",
    "\n",
    "            yield response.follow(next_page_url, callback=self.parse)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\"\"\"  \n",
    "        if next_page is not None:\n",
    "            if 'catalogue/' in next_page:\n",
    "                next_page_url = 'https://books.toscrape.com/' + next_page\n",
    "            else:\n",
    "                next_page_url = 'https://books.toscrape.com/catalogue/' + next_page\n",
    "\n",
    "            yield response.follow(next_page_url, callback=self.parse)\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "response.xpath(\"//ul[@class='breadcrumb']/li[@class='active']/preceding-sibling::li[1]/a/text()\").get()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Why is it when I copy the FULL X PATH for the Poetry element I get: \n",
    "/html/body/div/div/ul/li[3]/a\n",
    "\n",
    "JS Path: \n",
    "document.querySelector(\"#default > div > div > ul > li:nth-child(3) > a\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# BoilerPlate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'scrapy' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[1], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[38;5;28;01mclass\u001b[39;00m \u001b[38;5;21;01mQuotesSpider\u001b[39;00m(\u001b[43mscrapy\u001b[49m\u001b[38;5;241m.\u001b[39mSpider):\n\u001b[0;32m      2\u001b[0m     \u001b[38;5;66;03m# I need to title the class of this spider\u001b[39;00m\n\u001b[0;32m      3\u001b[0m     name \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mquotes\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m      5\u001b[0m     \u001b[38;5;66;03m# I need a function that is a list of URL pages to look at\u001b[39;00m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'scrapy' is not defined"
     ]
    }
   ],
   "source": [
    "class QuotesSpider(scrapy.Spider):\n",
    "    # I need to title the class of this spider\n",
    "    name = \"quotes\"\n",
    "\n",
    "    # I need a function that is a list of URL pages to look at\n",
    "    def start_requests(self):\n",
    "        urls = [\"https://quotes.toscrape.com/page/1/\",\n",
    "        \"https://quotes.toscrape.com/page/2/\"]\n",
    "\n",
    "# I need to iterate over each page\n",
    "        for url in urls:\n",
    "    \n",
    "    # I need to produce a SEQUENCE OF VALUES ( yield )\n",
    "            yield scrapy.Request(url=url,callback=self.parse)\n",
    "\n",
    "\n",
    "    def parse(self, response):\n",
    "        page = response.url.split(\"/\")[-2]\n",
    "        filename = f\"quotes-{page}.html\"\n",
    "        Path(filename).write_bytes(response.body)\n",
    "        self.log(f\"Saved file {filename}.\")\n",
    "\n",
    "    "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "virt",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
